All right.

We got to talk about Apple intelligence.

So, Apple's made this promise, this huge thing is

coming that's going to change everything across their whole lineup.

They've been talking about it for a while, and I think that promise is starting to fade.

This was first announced at WWDC 2024.

That was nearly six months ago, and it's still not completely out yet.

The new iPhone's launched in September with exactly zero

Apple intelligence features, but then some software updates have started to push

out, and eventually it's supposed to be finished and in everyone's hands by March 2025.

That's a lot of buildup.

So what I want to do now is review every single

Apple intelligence feature that's out so far.

And then also get into whether the promise

that they're actually making is even good in the first place.

So first up, writing tools.

So all of these features, unless otherwise specified, are on iPhone, iPad and Mac.

So no Apple Intelligence features at all on the Vision Pro.

their most faturistic platform.

That's already kind of fascinating.

But the writing tools, you may have heard about these since they're definitely

referenced a lot, maybe the most out of any of these.

And, yeah, it' it's basically generative AI

to help adjust what you've already written.

So this is easiest to demo on the Mac, but basically you have something

you've written, you highlight all of it, and then select one of the writing tools.

And actually, this is one of the first weird hiccups, just a strangely repetitive UI.

You can access any of the writing tools in one click right here

or hitch show writing tools, which again

shows the same list of writing tools.

Okay.

So I suppose there's a world where, you know, you write some message to

someone and you just want it to be a little more friendly or maybe you've typed

out a bunch of stuff that needs to be sent in a work email.

So you want to get the AI to make it more professional for you.

Sure, I guess.

So I've run it through various things that I've written from, you know, whole video scripts to just a bunch of messages.

And it works, technically.

I think the friendly mode mostly uses like shorter sentences and lots of exclamation points.

And then the professional mode

kind of does the opposite.

Like it's still pretty terse, but never uses exclamation points.

I think maybe concise is the most useful.

Basically it takes whatever you highlight and makes it maybe 40% shorter.

And then you can hit copy or just directly replace it if you trust it.

And each of these things takes about three or four seconds to

generate entirely on device, so it works offline as well.

The proof reading is nice because it picks up on extra things like

capitalization and proper nouns.

if you really need that on top of the auto punctuation checker

and then summary or make table would be

really nice for like really large documents, but it doesn't

seem to want to work on some of my huge documents

that would be nice to summarize or make into a table.

So

unfortunately, even as a basically a professional writer

at this point, I haven't gotten much use out of writing tools at all.

So notification summaries.

This one to me personally, I have found

almost useless.

Basically, it does exactly what it sounds like it does.

When it's enabled, it summarizes your notifications from each app.

So if you get a long message from someone or several notifications

in a row from a single app, it will do its best to condense that all into

a single message to help you kind of get the gist quickly.

So no matter how long or how short the

messages are, whether it's just a text or maybe a group chat has absolutely blown up and you missed 100 messages.

It's going to try to summarize all that

into one or two lines.

The thing is, once I enable it and start using it, it basically

seems like the notifications that I'm getting are almost never benefited

from being summarized or shortened.

Like I've never gotten four text messages that

are perfectly summarized into a single one.

And I'm sure it's possible There are going to be some instances where it works for people, but

it's not just me.

I've seen lots of examples online and there's plenty of memes, too, of Apple's

notifications, summaries doing some sometimes hilarious work, some brutal stuff.

So it works and I guess it's good for a laugh once in a while,

but yeah, this is a feature I straight up turned off.

Then Jen Moji.

So, okay, believe it or not,

there was some hype for this one.

And once again, it's basically exactly what it sounds like.

It's it's letting you generate any emoji using AI.

Anything you want.

So let's say I'm in messages and I want to react to some message with

a very specific emoji that doesn't exist.

You would describe an emoji, so you write

your text and then hit create a new emoji, give it

about three seconds again, and it will use generative AI to create that image for you.

That's

fun, I guess.

And yes, it will sometimes refuse to make what you ask of it.

If you ask for something like crazy or graphic, although it seems to

have no problem making a potato with a gun, so that's an emoji reaction you can send sick.

It's a very specific use case.

There's no doubt some people have fun with it.

I just think, I'm not in the target demographic to use this sort of thing all the time.

So

again, over my head, cool, it exists, but that's it.

So then image playground is another, maybe kind of weird one.

This is almost the same tool, but sort of standalone.

This is a playground to generate images in a cartoon style

of whatever you want.

So you open the playground app and again, just describe

the image you want in text.

Anything, really.

But before you type anything, there are also a number of these buttons

down here and there are kind of just inspiration suggestions for things or people

to include in the image.

So, yes, you can choose

any of the people that your phone recognizes from your photos app,

and that'll be the starting point for the image and then

add some themes or accessories or background or props or whatever on top of it.

So here's me with a hard

hat on, at a disco, and it generates it

again in a few seconds on device, always cartoon style,

never photoalistic, and it can give you a few options to choose from.

And once you hit done, you can copy and paste that image

wherever you want.

Google and a few others have this on their

devices too, just sort of sort of a playground to make some artificially generated images.

Again, it's of debatable usefulness.

Of course, it makes sense that it won't do photalistic images because that would open up a whole can of worms.

but it's even supposed to not do some things that could potentially be offensive again.

Like if you ask it for a gun, it typically refuses.

But I found if you add a few more variables like

a chef hat and some fireworks to something, then it

will be a little more likely to actually pull through for you.

So

yeah, good thing it says it's in beta and may create unexpected results.

This is yet another app that they've added to my phone that

I predict that I will probably never use again after making this video.

So then, priority notifications.

So, okay, now, this is one that I think had

some promise, or at least I'm in the target demographic for it because

as an iPhone and Android user, you start to notice that Apple's

weakness has, for a long time been notification management.

If it was just kind of had a fire hose and notifications coming in all the time.

So priority notifications surfaces certain

notifications above the rest when you're in a focus mode that reduces notifications.

But this should also work in the mail app to

put AI identified high priority messages up at the top plus some other categories.

So if you use the default mail app, which I don't, but a lot of people do, then this could be helpful.

Something Gmails had for many years.

And the reduced notifications mode also specifically

tries to do a good job of only letting important notifications through, but keeping the rest quiet.

So then the Photos app

yes, we all hate the new Phot app.

Everyone.

You do, I do, everyone you know hates it.

We're all on the same page.

It's terrible.

But Apple has added exactly one AI feature

to the Phot app in an age where lots of

companies are comfortable adding a ton of AI to their photos apps, dozens

of things, but they've decided, all right, yeah, we can do the background object removal thing.

We can do that.

So basically the same thing as Google's magic eraser tool, let's say you've

got a picture with a subject in the front and you just want to remove that annoying thing in the background.

You hit the edit button and then on the right side, you hit the cleanup tool.

And a lot of times it will automatically highlight in this sort of rainbow

glow the thing that it auto detects that you want to remove.

But if it doesn't, you can just tap or circle whatever you want and it takes a few seconds

and then it just gets rid of it and uses generative fill to fill in the background.

And of course, some scenes work better than others.

It's kind of the same deal as magic eraser or Photoshop.

Typically patterns or repeating backgrounds will give you the best results.

I'm going to say I actually think this one works better than Google's.

It's better at getting a good outline of the phot bomber

or the background object in a single gesture, which is nice.

It's really smart.

So to me, this is also one of the more useful features.

Recording summaries.

So, okay, this one had promised, but then was kind of confusing

to me because when I saw it on the list, I was like, oh, this, I would have loved this as a student.

This is amazing, just one place where you can record things, transcribe

them, and then summarize them and keep them for later.

That sounds amazing.

but this is not built into the default voice memos app at all.

So if you're on a phone call, you can turn on call recording.

You hit that little button down there.

It'll take a second.

It'll warn the person that you're on the phone with with a little message.

And then from there, it'll record everything that gets said and transcribe it.

And the transcriptions are amazing.

It identifies each speaker, it is accurate.

I love this part, but then, if you care about the summary

part, this is where it starts to get weird again, because you go into the notes that.

This is where it's saving everything, and it shows up as a new note,

and the preview actually summarizes it right here pretty well, but

then when you click in, there is a whole transcript, great.

and then there's another summary button up here at the top.

You hit that, and there's a different summary.

And this one's a little worse.

The first one back in the preview actually picked up and included that I said ridge wallet.

The second one didn't get that at all, but it did get Best Buy.

Interesting.

But Apple, why don't you bring this to the voice memos app?

This is I want to be able to sit this down in a lecture or a

meeting and have it record things so I can summarize them later.

That's like the main place I figured this would be useful, but it's not there.

So, please,

please.

The only way to initiate this right now is actually to go through

the notes app to create a new note and then attach and then

create a new recording and then record your audio into there.

But it just feels like it could be one step easier.

So okay, visual intelligence.

So these last two are kind of the big ones.

Visual intelligence is only available on the iPhone 16

and 16 Pro and you get to it by long pressing that button

on the side of those new phones, which opens it up.

It's that camera control button.

And when you open it up, you get a full screen view finder with three buttons, a shutter in the middle,

then ask on the left and search on the right.

So if you point this at any object or a subject and you hit ask,

that lets you ask ChatiPT anything about what it sees.

And if you hit search, then it's basically just reverse Google image searching, whatever it sees.

Sohati BT or Google.

So if you hit the shutter button, it snaps a photo and

then continues to give you those two items or a pop up menu

where you can again either search

or ask again, pretty repetitive, you ask me, but okay,

while this is a very pretty UI and it works pretty quickly, it

also isn't anything, you know, particularly new that we haven't seen before.

Like I was just watching like Galaxy S 8 review from back in

2017, where I do a demo of the exact same thing.

I take a picture of something in front of me.

It looks it up with Bixby AI and it could tell you if

it was a landmark or a product that you could shop for.

This is going to be more capable, obviously GPT

has a lot more capabilities and maybe even a little bit more trust

these days than Bixby had back then, and it's certainly more well integrated.

But yeah, so it's not something mind blowing or groundbreakingly

new, but it is ideally more accurate and more capable than before.

Maybe they're going to continue to build on top of this in the future.

But then there is Chati PT integration, the sort

of last but not least new thing, that's Siri, worse with ChatPT.

I think a lot of people thought there was a lot more to Siri, like right off the back because it has this new animation.

And you see the new Siri animation so you think it's the new Siri, but

most of the new Siri stuff isn't here yet.

But the chi PT stuff is.

So if you ever make a request or ask a question that's

out of the normal scope of Siri, maybe asked for

a recipe or you ask for it to make a trip itinerary or

something big, then it recognizes it and it can prompt you

if you want to ask Chatchi PT instead, and if you

confirm, then it pulls fromhatchi PT to respond.

This is all free.

You don't need an account for this.

Apple has promised all sorts of masking so your data is not used for training models.

Open AI doesn't get to collect any of this information about you through the requests.

But you can also sign into

your chatPT account if you want to keep a history of your

queries or use higher end models or even go over the daily limit of free queries.

There's even actually a button to upgrade to chat GPT

plus built into iOS now, so it's pretty well considered.

So yeah, the new Siri animation might be fooling some people, but really it's

other than being able to type to Siri more easily, there's really not a whole lot actually new yet with Siri.

But that brings me to

the rest of the things that aren't here yet

still, that are coming soon with software updates.

That list is right here.

There are more Apple intelligence features that are in the works coming soon.

And honestly, Siri is the main one I'm interested in because it's

supposed to be able to take in app actions.

It should be able to reach into apps and take action inside of

them, which I think could be

awesome.

I think developers could all update their apps to work

really well with it, and it could be really useful.

It could differentiate Siri to actually make it useful again.

But yeah, that's still coming.

But yeah, then from there, my take is the rest of the AI stuff

really not super amazing

or compelling to me just to be real.

Like the writing tools, that seems like a nice safe use of generative AI.

That's the thing they're sort of talking about the most, but

I don't even find myself needing to rewrite things that often.

And like I said, I'm not in the target demographic to use the

image playgrounds all that much or genis all the time.

The visual intelligence is definitely super useful like three

or four times a year for me, like when some interesting plant or dog

or whatever is in front of me and I want to just figure out what it is.

But that's actually funny.

Do you remember the clip from the Apple key note

of that person who walks up to a dog?

And instead of asking the person walking the dog, what kind of dog it is, they just go, hey, can I take a picture of your dog?

And then they ask the phone what kind of dog it is instead of just asking the person.

And that to me is the perfect encapsulation of so many of these Apple intelligence features.

You could use them,

and they might work really well, but should you should you

like you can ask for a more friendly version of this letter to send to your friend

or you could try to write it in a friendly way in the first

place like like you can ask

Chhat GPT to plan a whole trip for you with an itinerary and everything.

And honestly, it's really impressive when it works,

but are you actually going to just go in blind

and just follow the AI-generated itinerary?

If you even like packing, like I know there's two types of people when packing.

Maybe some people will just follow the ad generated prompt.

But I feel like I'm in the type that kind of wants a little bit more than that, I think.

Luckily, no matter what I'm packing, it always fits in my Ridge

travel gear, so shout out to Ridge for sponsoring this portion of the video.

Specifically, I help design the new commuter bag for Ridge.

And I actually I've been dailying this creation for the past couple months.

We got it some really good water bottle holders on the sides now and

I also added a tablet sleeve in the back, so if you've got a tablet and a

laptop, they both have their own padded slot.

And then I doubled down when I'm flying because I also have

the ridge carry on, which is basically perfect.

It's weather proof, it's rugged.

It's got, you know, these aluminum corner protectors.

It also has the 360 spinning wheels.

They're super smooth.

Of course, it has a slot for a tracker in case it's ever separated from you.

It's incredibly light weight.

It's the go-to, and you ready to know that they work perfectly together like

a little ecosystem to create a perfect little travel combo.

So shout out to Ridge for sponsoring this portion of the video and for letting

me design some of these products and some more that are upcoming,

so we'll have to stay tuned for those.

But if you want to pick up both the carry-on and the backpack,

you can get them together at Ridge.com slash MKBHD and get 30% off.

And they also have their Black Friday sale going on right now.

But yeah, I think Apple

is going to build on and sort of iterate on

hopefully all of these features.

Like we have this sort of standard set that we're expecting from them

now and this is this is the worst they'll ever be that will only get better from here.

But it is pretty crazy to see how much emphasis is in all of the advertising

and all the talk about the newest devices on apple.com

as if Apple intelligence is this massive game changing, groundbreaking new thing.

You know, there are parts of it that are really good.

I think the background eraser tool in photos is probably the best we've seen.

It's better than Google's.

It's really impressive.

I think the visual intelligence stuff has potential to be really good,

but honestly, the best thing I think we've gotten from Apple Intelligence,

because all this stuff is running on device, is bumping up the base memory in everything.

There's more ram in every iPhone now and the bass memory

on every Mac is 16 gigs now, which made the bass Mac mini an incredible deal.

So

shout out to Apple Intelligence for that.

Either way, hopefully a lot more coming.

Thanks for watching.

Get you guys the next one.

Peace.

